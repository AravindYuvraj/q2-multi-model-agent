 A multimodal QA web app that allows users to upload images and ask questions about them using vision-capable AI models.

Follow these steps to run this app:

```sh
# Step 1: Clone the repository using the project's Git URL.
git clone https://github.com/AravindYuvraj/q2-multi-model-agent.git


# Step 2: Install the necessary dependencies.
npm i

# Step 3: Start the development server with auto-reloading and an instant preview.
npm run dev
```
1. App Preview
<img width="939" alt="Screenshot 2025-06-26 140307" src="https://github.com/user-attachments/assets/e3d62875-30e7-4d31-959d-539fb7d49d4d" />

2. Upload any image
<img width="629" alt="image_upload" src="https://github.com/user-attachments/assets/e3b5eb37-2be5-402d-9b49-687213a4137c" />


3. Ask your question
<img width="617" alt="ask" src="https://github.com/user-attachments/assets/2d0f8bb1-a3d4-486f-9f3c-6b7e986c640b" />


4. Get the response
<img width="643" alt="get_response" src="https://github.com/user-attachments/assets/9d8897de-297e-46c6-8fda-06f2979bc7fb" />


### I used Gemini 2.0 model

## Sample Outputs
1. <img width="632" alt="image" src="https://github.com/user-attachments/assets/4e3031df-7015-412c-8922-3ca128f1af20" />

2. <img width="623" alt="image" src="https://github.com/user-attachments/assets/49f52617-2083-4b75-a178-037edee98451" />

3. <img width="639" alt="image" src="https://github.com/user-attachments/assets/9a464a88-2346-4c13-9d3f-6c6eee01e4a3" />
